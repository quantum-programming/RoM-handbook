{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from exputils.dot.dot_product import compute_all_dot_products\n",
    "from exputils.RoM.dot import calculate_RoM_dot\n",
    "from exputils.st_norm import lb_by_st_norm\n",
    "from exputils.state.canonical_magic_state import (\n",
    "    make_canonical_magic_state_in_pauli_basis,\n",
    ")\n",
    "from exputils.state.random import make_random_quantum_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lb_by_dot(n_qubit, rho_vec):\n",
    "    dots = compute_all_dot_products(n_qubit, rho_vec)\n",
    "    dp = np.max(dots)\n",
    "    dm = np.min(dots)\n",
    "    assert np.isclose(rho_vec.T @ rho_vec, np.linalg.norm(rho_vec, ord=2) ** 2)\n",
    "    return 1 + 2 * max(0, (np.linalg.norm(rho_vec, ord=2) ** 2 - dp) / (dp - dm))\n",
    "\n",
    "\n",
    "def lb_by_stabilizer_fidelity(n_qubit, rho_vec):\n",
    "    # valid only when the state is pure\n",
    "    dots = compute_all_dot_products(n_qubit, rho_vec)\n",
    "    stabilizer_fidelity = np.max(dots) / (2**n_qubit)\n",
    "    return (rho_vec.T @ rho_vec) / (2**n_qubit) / stabilizer_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lb_sf=1.7848266417977787\n",
      "lb_dot=2.569657374921798\n",
      "lb_sf=2.08796162723462\n",
      "lb_dot=3.1759245565249876\n",
      "lb_sf=1.9674600518646173\n",
      "lb_dot=2.9349272623431193\n",
      "lb_sf=1.6791792186872823\n",
      "lb_dot=2.3583595598779716\n",
      "lb_sf=1.6942965885644283\n",
      "lb_dot=2.388595043312849\n",
      "lb_sf=1.9150265864033176\n",
      "lb_dot=2.8300637956780155\n",
      "lb_sf=2.135936687642714\n",
      "lb_dot=3.2718786047297663\n",
      "lb_sf=1.7228550010730312\n",
      "lb_dot=2.445711429770231\n",
      "lb_sf=1.8867955901216764\n",
      "lb_dot=2.773593577232412\n",
      "lb_sf=2.060172114354628\n",
      "lb_dot=3.120355090833797\n",
      "lb_sf=2.0333549243360434\n",
      "lb_dot=3.0667122636818833\n",
      "lb_sf=2.0916832393016875\n",
      "lb_dot=3.1833734530904687\n",
      "lb_sf=2.281815928762279\n",
      "lb_dot=3.5636376453388627\n",
      "lb_sf=2.0788567973664582\n",
      "lb_dot=3.1577323381835973\n",
      "lb_sf=1.9684029043039881\n",
      "lb_dot=2.9368181998678278\n",
      "lb_sf=1.8311579989390963\n",
      "lb_dot=2.662327136672008\n",
      "lb_sf=1.7794862789173738\n",
      "lb_dot=2.558974192985572\n",
      "lb_sf=2.0817902791754554\n",
      "lb_dot=3.1635937950736914\n",
      "lb_sf=2.2845795573570227\n",
      "lb_dot=3.5691910877007254\n",
      "lb_sf=1.9774830843826663\n",
      "lb_dot=2.95496898044997\n",
      "lb_sf=2.0896421815648547\n",
      "lb_dot=3.1793027667906024\n",
      "lb_sf=2.156462392645488\n",
      "lb_dot=3.3129254603740965\n",
      "lb_sf=2.033233557283172\n",
      "lb_dot=3.066470810774231\n",
      "lb_sf=1.9185550643434715\n",
      "lb_dot=2.837116097169239\n",
      "lb_sf=1.9824137039627765\n",
      "lb_dot=2.9648298364054617\n",
      "lb_sf=1.9890637282347294\n",
      "lb_dot=2.978128489925452\n",
      "lb_sf=2.2569531907150826\n",
      "lb_dot=3.5139067148156586\n",
      "lb_sf=2.0536285608362843\n",
      "lb_dot=3.107276034753809\n",
      "lb_sf=2.1214170446475076\n",
      "lb_dot=3.2428528596950166\n",
      "lb_sf=1.7632065623690967\n",
      "lb_dot=2.5264151261255394\n",
      "lb_sf=2.1052529135081897\n",
      "lb_dot=3.210507903175462\n",
      "lb_sf=1.8838199638422901\n",
      "lb_dot=2.7676409341699815\n",
      "lb_sf=2.0470193067881537\n",
      "lb_dot=3.094046208158192\n",
      "lb_sf=2.0226982773538866\n",
      "lb_dot=3.0454170689411844\n",
      "lb_sf=1.969326064841702\n",
      "lb_dot=2.9386566461038632\n",
      "lb_sf=2.0917449940876693\n",
      "lb_dot=3.183504379204331\n",
      "lb_sf=2.0662224605100383\n",
      "lb_dot=3.1324449434306634\n",
      "lb_sf=1.95063454702251\n",
      "lb_dot=2.9012731585708056\n",
      "lb_sf=2.0024529986528017\n",
      "lb_dot=3.0049353228352507\n",
      "lb_sf=1.9054177734893882\n",
      "lb_dot=2.8108460175712318\n",
      "lb_sf=1.7215761683472643\n",
      "lb_dot=2.4431576952465344\n",
      "lb_sf=2.0323526838765367\n",
      "lb_dot=3.0647204821779095\n",
      "lb_sf=1.8328414441316496\n",
      "lb_dot=2.6656841543049796\n",
      "lb_sf=1.9658696166383445\n",
      "lb_dot=2.931740741068148\n",
      "lb_sf=1.9597893261823771\n",
      "lb_dot=2.9196038836583487\n",
      "lb_sf=2.0173579512576216\n",
      "lb_dot=3.0347403462784652\n",
      "lb_sf=1.645938747840129\n",
      "lb_dot=2.29188455759841\n",
      "lb_sf=1.7001311311610923\n",
      "lb_dot=2.4002735352866313\n",
      "lb_sf=1.9759252352709777\n",
      "lb_dot=2.951850618877807\n",
      "lb_sf=1.723290891376198\n",
      "lb_dot=2.4465840266584937\n",
      "lb_sf=1.8637426585139594\n",
      "lb_dot=2.727485486414207\n",
      "lb_sf=1.9276460086573857\n",
      "lb_dot=2.8552978581981545\n",
      "lb_sf=1.9755117427498465\n",
      "lb_dot=2.9510303787414633\n",
      "lb_sf=1.7391308107715155\n",
      "lb_dot=2.4782629159033056\n",
      "lb_sf=2.0030297263835646\n",
      "lb_dot=3.006062343276552\n",
      "lb_sf=1.9588979053287356\n",
      "lb_dot=2.9177959073681548\n",
      "lb_sf=1.9586986858629214\n",
      "lb_dot=2.9174019697151277\n",
      "lb_sf=2.00176332905534\n",
      "lb_dot=3.003538864767604\n",
      "lb_sf=1.7252934407995262\n",
      "lb_dot=2.4505888612592845\n",
      "lb_sf=1.761200544052914\n",
      "lb_dot=2.5224057844054095\n",
      "lb_sf=1.6845887498241587\n",
      "lb_dot=2.369180500797535\n",
      "lb_sf=1.562689580010639\n",
      "lb_dot=2.1253828462834132\n",
      "lb_sf=2.173638804016827\n",
      "lb_dot=3.3472806394097665\n",
      "lb_sf=2.0665941191945874\n",
      "lb_dot=3.1331977416807804\n",
      "lb_sf=1.6400185514999268\n",
      "lb_dot=2.280039781053408\n",
      "lb_sf=2.0607630658336498\n",
      "lb_dot=3.1215367558942564\n",
      "lb_sf=1.8994114136398685\n",
      "lb_dot=2.798839662389307\n",
      "lb_sf=2.107986131200357\n",
      "lb_dot=3.2159782546286646\n",
      "lb_sf=1.9631396436641335\n",
      "lb_dot=2.9262959954435495\n",
      "lb_sf=1.8838575398010564\n",
      "lb_dot=2.7677182600481336\n",
      "lb_sf=1.968945000233878\n",
      "lb_dot=2.937891142521775\n",
      "lb_sf=1.781023038254738\n",
      "lb_dot=2.5620466602215437\n",
      "lb_sf=1.9946356007218051\n",
      "lb_dot=2.9892739848954664\n",
      "lb_sf=1.6600138518677974\n",
      "lb_dot=2.320035336731041\n",
      "lb_sf=2.159531334622343\n",
      "lb_dot=3.3190721515037924\n",
      "lb_sf=2.2182013991079104\n",
      "lb_dot=3.436419821160994\n",
      "lb_sf=1.9289731552927682\n",
      "lb_dot=2.8579488194220657\n",
      "lb_sf=2.0042553687277267\n",
      "lb_dot=3.0085220406189035\n",
      "lb_sf=2.009536160158297\n",
      "lb_dot=3.0190794107084358\n",
      "lb_sf=1.7249216724940624\n",
      "lb_dot=2.4498474792083966\n",
      "lb_sf=2.0637001876768375\n",
      "lb_dot=3.127410687423396\n",
      "lb_sf=1.5089403893401387\n",
      "lb_dot=2.0178839977407\n",
      "lb_sf=1.713241210008255\n",
      "lb_dot=2.4264862738668\n",
      "lb_sf=1.8665971377816823\n",
      "lb_dot=2.733198668942782\n",
      "lb_sf=1.9833025740787324\n",
      "lb_dot=2.96660879693125\n",
      "lb_sf=1.9863161978464285\n",
      "lb_dot=2.9726359792389063\n",
      "lb_sf=1.9921025101245717\n",
      "lb_dot=2.9842139002938817\n",
      "lb_sf=2.006350550273425\n",
      "lb_dot=3.012710767700614\n",
      "lb_sf=1.8157300156738394\n",
      "lb_dot=2.6314798939137933\n",
      "lb_sf=2.191022182711602\n",
      "lb_dot=3.382049264791613\n",
      "lb_sf=1.8773941863857733\n",
      "lb_dot=2.754797060145015\n",
      "lb_sf=1.8614236506086457\n",
      "lb_dot=2.7228565452848748\n",
      "lb_sf=2.074731980716289\n",
      "lb_dot=3.1494714202912393\n",
      "lb_sf=1.9935521480035543\n",
      "lb_dot=2.9871239027983796\n",
      "lb_sf=1.9620330069543126\n",
      "lb_dot=2.9240750508907896\n",
      "lb_sf=2.106145799326775\n",
      "lb_dot=3.2122981619187345\n",
      "lb_sf=1.567769231988254\n",
      "lb_dot=2.1355399840763356\n",
      "lb_sf=1.844504744442277\n",
      "lb_dot=2.6890119569644204\n",
      "lb_sf=1.794271512244608\n",
      "lb_dot=2.588553323244854\n",
      "lb_sf=2.1877146750061525\n",
      "lb_dot=3.375451797917317\n",
      "best_lb_count={'sf': 0, 'st': 96, 'dot': 4}\n",
      "lb_sf=0.9356083041632701\n",
      "lb_dot=1\n",
      "lb_sf=0.8575515742393719\n",
      "lb_dot=1\n",
      "lb_sf=0.8888352443939529\n",
      "lb_dot=1\n",
      "lb_sf=0.8562632886557999\n",
      "lb_dot=1\n",
      "lb_sf=0.9005499841621653\n",
      "lb_dot=1\n",
      "lb_sf=0.9169440990026339\n",
      "lb_dot=1\n",
      "lb_sf=0.9269260248768022\n",
      "lb_dot=1\n",
      "lb_sf=0.855713356683018\n",
      "lb_dot=1\n",
      "lb_sf=0.9740505368194093\n",
      "lb_dot=1\n",
      "lb_sf=0.8709738867295576\n",
      "lb_dot=1\n",
      "lb_sf=0.8391214172386426\n",
      "lb_dot=1\n",
      "lb_sf=0.8928611419190265\n",
      "lb_dot=1\n",
      "lb_sf=0.9052356007950116\n",
      "lb_dot=1\n",
      "lb_sf=0.891089856605415\n",
      "lb_dot=1\n",
      "lb_sf=0.9235637995621133\n",
      "lb_dot=1\n",
      "lb_sf=0.8817220055322883\n",
      "lb_dot=1\n",
      "lb_sf=0.9972528755490951\n",
      "lb_dot=1\n",
      "lb_sf=0.7967126027982782\n",
      "lb_dot=1\n",
      "lb_sf=0.8690520637976122\n",
      "lb_dot=1\n",
      "lb_sf=0.90350721413766\n",
      "lb_dot=1\n",
      "lb_sf=0.965449046083298\n",
      "lb_dot=1\n",
      "lb_sf=0.9252430763694106\n",
      "lb_dot=1\n",
      "lb_sf=0.8540883171457379\n",
      "lb_dot=1\n",
      "lb_sf=0.9351006052454994\n",
      "lb_dot=1\n",
      "lb_sf=0.898590267340505\n",
      "lb_dot=1\n",
      "lb_sf=0.9050174684845159\n",
      "lb_dot=1\n",
      "lb_sf=0.8132601155649394\n",
      "lb_dot=1\n",
      "lb_sf=0.9260086966034997\n",
      "lb_dot=1\n",
      "lb_sf=0.8644151911158217\n",
      "lb_dot=1\n",
      "lb_sf=0.9165564491615246\n",
      "lb_dot=1\n",
      "lb_sf=0.8528504684873359\n",
      "lb_dot=1\n",
      "lb_sf=0.8748811732812876\n",
      "lb_dot=1\n",
      "lb_sf=0.8643562914964892\n",
      "lb_dot=1\n",
      "lb_sf=0.8494215787913377\n",
      "lb_dot=1\n",
      "lb_sf=0.9551531090332588\n",
      "lb_dot=1\n",
      "lb_sf=0.8542903877079838\n",
      "lb_dot=1\n",
      "lb_sf=0.7928093959388096\n",
      "lb_dot=1\n",
      "lb_sf=0.8641723239250068\n",
      "lb_dot=1\n",
      "lb_sf=0.882333979643826\n",
      "lb_dot=1\n",
      "lb_sf=0.957892385294374\n",
      "lb_dot=1\n",
      "lb_sf=0.8760807686657247\n",
      "lb_dot=1\n",
      "lb_sf=0.9133024999731546\n",
      "lb_dot=1\n",
      "lb_sf=0.8410990392049288\n",
      "lb_dot=1\n",
      "lb_sf=0.9142304447759425\n",
      "lb_dot=1\n",
      "lb_sf=0.9312990693704555\n",
      "lb_dot=1\n",
      "lb_sf=0.9497323785180464\n",
      "lb_dot=1\n",
      "lb_sf=0.9184174953273131\n",
      "lb_dot=1\n",
      "lb_sf=0.892127963159293\n",
      "lb_dot=1\n",
      "lb_sf=0.8105785022679667\n",
      "lb_dot=1\n",
      "lb_sf=0.9254693692849503\n",
      "lb_dot=1\n",
      "lb_sf=0.9017634238819701\n",
      "lb_dot=1\n",
      "lb_sf=0.8294229537365493\n",
      "lb_dot=1\n",
      "lb_sf=0.8791634314547149\n",
      "lb_dot=1\n",
      "lb_sf=0.9273016745694328\n",
      "lb_dot=1\n",
      "lb_sf=0.9040991072322055\n",
      "lb_dot=1\n",
      "lb_sf=0.9105561466382392\n",
      "lb_dot=1\n",
      "lb_sf=0.9112169991584387\n",
      "lb_dot=1\n",
      "lb_sf=0.8513919396723068\n",
      "lb_dot=1\n",
      "lb_sf=0.7835062683766102\n",
      "lb_dot=1\n",
      "lb_sf=0.9112237030725986\n",
      "lb_dot=1\n",
      "lb_sf=0.9194306222021822\n",
      "lb_dot=1\n",
      "lb_sf=0.9387845418201125\n",
      "lb_dot=1\n",
      "lb_sf=0.8542365101767246\n",
      "lb_dot=1\n",
      "lb_sf=0.9499716968514939\n",
      "lb_dot=1\n",
      "lb_sf=0.8537534003708174\n",
      "lb_dot=1\n",
      "lb_sf=0.9026550881162635\n",
      "lb_dot=1\n",
      "lb_sf=0.8749383494791094\n",
      "lb_dot=1\n",
      "lb_sf=0.8872441313717371\n",
      "lb_dot=1\n",
      "lb_sf=0.841314742605856\n",
      "lb_dot=1\n",
      "lb_sf=0.8978515199978859\n",
      "lb_dot=1\n",
      "lb_sf=0.7983475177103377\n",
      "lb_dot=1\n",
      "lb_sf=0.8119596053549731\n",
      "lb_dot=1\n",
      "lb_sf=0.9593502321173472\n",
      "lb_dot=1\n",
      "lb_sf=0.8847708592653906\n",
      "lb_dot=1\n",
      "lb_sf=0.9051974656095461\n",
      "lb_dot=1\n",
      "lb_sf=0.9103797458832039\n",
      "lb_dot=1\n",
      "lb_sf=0.8210857523197151\n",
      "lb_dot=1\n",
      "lb_sf=0.9620674780686431\n",
      "lb_dot=1\n",
      "lb_sf=0.8952474481474012\n",
      "lb_dot=1\n",
      "lb_sf=0.884762330929279\n",
      "lb_dot=1\n",
      "lb_sf=0.9284887502371153\n",
      "lb_dot=1\n",
      "lb_sf=0.9282403377202783\n",
      "lb_dot=1\n",
      "lb_sf=0.8664000502507124\n",
      "lb_dot=1\n",
      "lb_sf=0.8759110124816489\n",
      "lb_dot=1\n",
      "lb_sf=0.7911488882748836\n",
      "lb_dot=1\n",
      "lb_sf=0.8647585240098349\n",
      "lb_dot=1\n",
      "lb_sf=0.9210178823260715\n",
      "lb_dot=1\n",
      "lb_sf=0.8213139082441011\n",
      "lb_dot=1\n",
      "lb_sf=0.8507395483779905\n",
      "lb_dot=1\n",
      "lb_sf=0.8954016194549822\n",
      "lb_dot=1\n",
      "lb_sf=0.9188511238933738\n",
      "lb_dot=1\n",
      "lb_sf=0.9295676033950752\n",
      "lb_dot=1\n",
      "lb_sf=0.7704698815211203\n",
      "lb_dot=1\n",
      "lb_sf=0.8939531513417006\n",
      "lb_dot=1\n",
      "lb_sf=0.8853001188638028\n",
      "lb_dot=1\n",
      "lb_sf=0.8926670269578904\n",
      "lb_dot=1\n",
      "lb_sf=0.9557324063228818\n",
      "lb_dot=1\n",
      "lb_sf=0.8885674819174417\n",
      "lb_dot=1\n",
      "lb_sf=0.9192227478733174\n",
      "lb_dot=1\n",
      "lb_sf=0.8267981471961248\n",
      "lb_dot=1\n",
      "best_lb_count={'sf': 0, 'st': 1, 'dot': 99}\n"
     ]
    }
   ],
   "source": [
    "n_qubit = 4\n",
    "\n",
    "for kind in [\"pure\", \"mixed\"]:\n",
    "    best_lb_count = dict()\n",
    "    best_lb_count[\"sf\"] = 0\n",
    "    best_lb_count[\"st\"] = 0\n",
    "    best_lb_count[\"dot\"] = 0\n",
    "    for seed in range(100):\n",
    "        rho_vec = make_random_quantum_state(kind, n_qubit, seed=seed)\n",
    "        RoM, coeff, Amat = calculate_RoM_dot(n_qubit, rho_vec, method=\"gurobi\")\n",
    "        # print(\"RoM = \", RoM)\n",
    "\n",
    "        p = (RoM - 1) / 2\n",
    "        rho_p = np.sum(coeff[coeff > 0] * Amat[:, coeff > 0].toarray(), axis=1)\n",
    "        rho_m = np.sum(coeff[coeff < 0] * Amat[:, coeff < 0].toarray(), axis=1)\n",
    "        assert np.allclose(rho_p + rho_m, rho_vec)\n",
    "        assert np.isclose(rho_p[0], 1 + p)\n",
    "        assert np.isclose(rho_m[0], -p)\n",
    "        rho_p /= 1 + p\n",
    "        rho_m /= -p\n",
    "        assert np.allclose((1 + p) * rho_p + (-p) * rho_m, rho_vec)\n",
    "        assert np.isclose(rho_p[0], 1)\n",
    "        assert np.isclose(rho_m[0], 1)\n",
    "\n",
    "        # print(f\"{p=}\")\n",
    "        # print(f\"{np.dot(rho_vec, rho_p)=}\")\n",
    "        # print(f\"{np.dot(rho_vec, rho_m)=}\")\n",
    "\n",
    "        dp = np.dot(rho_vec, rho_p)\n",
    "        dm = np.dot(rho_vec, rho_m)\n",
    "        # print(f\"{np.linalg.norm(rho_vec, ord=2) ** 2=}\")\n",
    "        assert np.isclose(p, (np.linalg.norm(rho_vec, ord=2) ** 2 - dp) / (dp - dm))\n",
    "\n",
    "        lb_sf = lb_by_stabilizer_fidelity(n_qubit, rho_vec)\n",
    "        lb_st = lb_by_st_norm(n_qubit, rho_vec)\n",
    "        lb_dot = lb_by_dot(n_qubit, rho_vec)\n",
    "\n",
    "        best_lb = (0.0, \"None\")\n",
    "\n",
    "        print(f\"{lb_sf=}\")\n",
    "        assert lb_sf <= RoM\n",
    "        if lb_sf > best_lb[0]:\n",
    "            best_lb = (lb_sf, \"sf\")\n",
    "\n",
    "        # print(f\"{lb_st=}\")\n",
    "        print(f\"{lb_dot=}\")\n",
    "        assert lb_st <= RoM\n",
    "        assert lb_dot <= RoM\n",
    "\n",
    "        if lb_st > best_lb[0]:\n",
    "            best_lb = (lb_st, \"st\")\n",
    "        if lb_dot > best_lb[0]:\n",
    "            best_lb = (lb_dot, \"dot\")\n",
    "\n",
    "        best_lb_count[best_lb[1]] += 1\n",
    "\n",
    "    print(f\"{best_lb_count=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the $\\langle\\langle \\rho|\\rho \\rangle\\rangle \\leq \\langle\\langle\\rho|\\rho_{\\text{max}} \\rangle\\rangle$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho_vec=array([1.        , 0.70710678, 0.70710678, 0.        ])\n",
      "RoM=1.414213562373095\n",
      "Amat.toarray()=array([[ 1,  1,  1],\n",
      "       [ 1, -1,  0],\n",
      "       [ 0,  0,  1],\n",
      "       [ 0,  0,  0]], dtype=int8)\n",
      "coeff=array([ 0.5       , -0.20710678,  0.70710678])\n",
      "rho_vec.T @ rho_vec=2.0\n",
      "max(compute_all_dot_products(n_qubit, rho_vec))=1.7071067811865475\n",
      "col @ rho_vec * coeff[i]=0.8535533905932737\n",
      "col @ rho_vec * coeff[i]=-0.06066017177982128\n",
      "col @ rho_vec * coeff[i]=1.2071067811865475\n"
     ]
    }
   ],
   "source": [
    "n_qubit = 1\n",
    "rho_vec = make_canonical_magic_state_in_pauli_basis(n_qubit).toarray().flatten()\n",
    "print(f\"{rho_vec=}\")\n",
    "\n",
    "RoM, coeff, Amat = calculate_RoM_dot(n_qubit, rho_vec, method=\"gurobi\")\n",
    "assert RoM == np.linalg.norm(coeff, ord=1)\n",
    "print(f\"{RoM=}\")\n",
    "print(f\"{Amat.toarray()=}\")\n",
    "print(f\"{coeff=}\")\n",
    "\n",
    "print(f\"{rho_vec.T @ rho_vec=}\")\n",
    "print(f\"{max(compute_all_dot_products(n_qubit, rho_vec))=}\")\n",
    "\n",
    "for i, col in enumerate(Amat.toarray().T):\n",
    "    assert 0 <= col @ rho_vec <= (2**n_qubit)\n",
    "    print(f\"{col @ rho_vec * coeff[i]=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check with H state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lb_by_stabilizer_fidelity(n_qubit, rho_vec)=2.5859245482734514\n",
      "lb_by_st_norm(n_qubit, rho_vec)=3.1269039581923277\n",
      "lb_by_dot(n_qubit, rho_vec)=4.171849096546902\n"
     ]
    }
   ],
   "source": [
    "n_qubit = 6\n",
    "rho_vec = make_canonical_magic_state_in_pauli_basis(n_qubit).toarray().flatten()\n",
    "\n",
    "print(f\"{lb_by_stabilizer_fidelity(n_qubit, rho_vec)=}\")\n",
    "print(f\"{lb_by_st_norm(n_qubit, rho_vec)=}\")\n",
    "print(f\"{lb_by_dot(n_qubit, rho_vec)=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "lb_by_st_norm(n_qubit, rho_vec)=3.1269039581923277\n",
    "lb_by_dot(n_qubit, rho_vec)=4.171849096546902\n",
    "true_RoM=4.73894\n",
    "```\n",
    "\n",
    "We get the better lower bound by using the dot product.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StabilizerSimulator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
